## Collections类

---
- [Collections类](#collections%e7%b1%bb)
  - [Collection包的整体结构](#collection%e5%8c%85%e7%9a%84%e6%95%b4%e4%bd%93%e7%bb%93%e6%9e%84)
  - [HashMap](#hashmap)
    - [HashMap中的常量](#hashmap%e4%b8%ad%e7%9a%84%e5%b8%b8%e9%87%8f)
    - [构造器](#%e6%9e%84%e9%80%a0%e5%99%a8)
    - [tableSizeFor()与容量大小](#tablesizefor%e4%b8%8e%e5%ae%b9%e9%87%8f%e5%a4%a7%e5%b0%8f)
    - [put函数](#put%e5%87%bd%e6%95%b0)
    - [hash函数](#hash%e5%87%bd%e6%95%b0)
    - [put的实际执行函数putVal](#put%e7%9a%84%e5%ae%9e%e9%99%85%e6%89%a7%e8%a1%8c%e5%87%bd%e6%95%b0putval)
    - [resize方法](#resize%e6%96%b9%e6%b3%95)
    - [树化Treeify](#%e6%a0%91%e5%8c%96treeify)
    - [HashMap常考知识点总结](#hashmap%e5%b8%b8%e8%80%83%e7%9f%a5%e8%af%86%e7%82%b9%e6%80%bb%e7%bb%93)
  - [LinkedHashMap](#linkedhashmap)
    - [Constructor](#constructor)
    - [Entry](#entry)
    - [添加和删除](#%e6%b7%bb%e5%8a%a0%e5%92%8c%e5%88%a0%e9%99%a4)
    - [按照访问顺序排序](#%e6%8c%89%e7%85%a7%e8%ae%bf%e9%97%ae%e9%a1%ba%e5%ba%8f%e6%8e%92%e5%ba%8f)
    - [将最久没有访问的节点删除](#%e5%b0%86%e6%9c%80%e4%b9%85%e6%b2%a1%e6%9c%89%e8%ae%bf%e9%97%ae%e7%9a%84%e8%8a%82%e7%82%b9%e5%88%a0%e9%99%a4)
    - [LinkedHashMap 手写LRU](#linkedhashmap-%e6%89%8b%e5%86%99lru)


Java中的Collection包是JDK中非常重要的一个包, 自顶向下的Collection包的常用数据结构之间的关系结构如下.

### Collection包的整体结构
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200222150732183.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzM3NDA3NTg3,size_16,color_FFFFFF,t_70)
Collection自身是一个接口, 是对集合这一概念的抽象, 提供的常用API有:
- add(Object obj) 向Collection添加元素
- remove(obj) 如果obj在集合中, 将其移除
- contains(obj) 判断是否包含
- clear()
- size()
- isEmpty()
- iterator() 返回对集合元素的迭代器
- addAll(Collection<? extends E> c) 将一个集合的元素添加到该集合中
- containsAll(Collection<? extends E> c)
- retainAll(Collection c) 只保留集合里面包含的
- removeIf(Predicate<? super E> filter) [这个方法很香, 不用自己迭代了]

Collection下, 有三个重要的接口分别是`Set`, `List`, `Map`, 所代表的分别是无重复的集合, 有序集合和键值对集合的集合的子集. 其分别提供的API有

- Set 和Colleciton的概念最接近, 区别在于Set中无重复, API几乎一致
- List list的特点是有序, 链表, 需要考虑的性能问题是是否支持随机访问, 增删的时间复杂度这些, 因为是有序的, 其API额外提供了一些和索引相关的内容
	- add(index, obj) 在index位置添加
	- remove(index) 删除index位置的元素
	- set(index, obj) 修改...
	- get(index) 获取index位置的对象
	- indexOf(obj) list中第一个obj的下标
- Queue 队列接口是队列数据结构的抽象, 队尾加, 队首减, 提供的API有加减和查队首元素的, 有两套api出现异常时, 一套会抛Exception, 一套只返回null
	- add(obj) & offer(obj) 在队尾添加元素
	- remove() & poll() 从队首移除元素
	- element() & peek() 获得队首元素但不移除
- Map 映射接口并不继承于Colleciton, 不是广义的Collection, 其存储的是键值对, 因此API增加了对键和值的操作, 增删该查也有所不同
	- put(k, v) , putIfAbsent(k,v) 增和改
	- replace(k, v), replace(k, ov, nv) 只能在存在时才能改
	- remove(k), remove(k, v) 只有都对上才删除
	- get(k), getOrDefault(k) 查
	- compute(k, function) 对键值对进行计算
	- containsKey(k)
	- containsValue(v)
	- keySet()
	- entrySet()
	- values()

### HashMap
在了解`HashMap`之前, 首先谈一谈经常和它一起出现的`HashTable`.`Hashtable` 是早期 Java 类库提供的一个哈希表实现，本身是同步的，不支持 null 键和值，由于同步导致的性能开销，所以已经很少被推荐使用. `TreeMap`是基于红黑树实现的Map类, 其`put`,`get`操作的时间复杂度在O(logN), 但是它的键值存储是有序的, 顺序与`compareTo`或`Comparator`有关.

下面是Map家族的结构概览
![在这里插入图片描述](https://img-blog.csdnimg.cn/2020022216291812.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzM3NDA3NTg3,size_16,color_FFFFFF,t_70)
在以上的类中, 如果需要常数时间复杂度的增删改查, 并且对顺序没有要求, 最常用的就是`HashMap`类. 哈希是通过哈希函数, 将任意长度的输入变成固定长度的输出, `HashMap`正是利用这一性质, 将键值对的特征(hash)转化为固定长度的整型输出, 将输出作为数组下标, 将键值对存储到数组中, 由于数组的随机访问的性能, 能够保证其常数时间的读写. 

用到hash的地方, 必须要考虑的问题就是哈希冲突的解决, 哈希冲突的解决思路有以下几种:
- 开放定址法:  当发生冲突时, 采用线性探测或二次探测等方法, 在初始位置的周围寻找一个空的位置放置. 封闭哈希, 元素数量不能超过桶数量, 高负载下性能下降严重
- 再哈希法: 当第一个hash函数产生的值发生碰撞, 用第二个hash函数再产生一个值
- 链地址法: 也就是拉链法, 每个地址相当于一个桶, 当发生冲突时, 还是将键值对放到桶中, 同一个桶的键值对构成链表. 适用频繁插入删除的情况
- 溢出区法: 专门建立一个溢出区, 将发生碰撞的元素用链表存储起来. 和拉链法的思想相似, 但是溢出集中时, 性能不如拉链法. 

`HashMap`采用的方法是拉链法, 当同时当元素数/桶数达到一定比例(负载因子)时, 进行扩容. 接下来分析源码. 以下分析基于JDK1.8

#### HashMap中的常量
首先是HashMap中有几个重要的常量
```java
static final int DEFAULT_INITIAL_CAPACITY = 1 << 4; // 16 HashMap的默认初始容量
static final int MAXIMUM_CAPACITY = 1 << 30; // HashMap的最大容量
static final float DEFAULT_LOAD_FACTOR = 0.75f;  // 推荐的负载因子, 通常情况下, 不用修改
static final int TREEIFY_THRESHOLD = 8; // 单个桶中元素数量, 达到树化门限则会从链表调整为红黑树, 防止哈希碰撞拒绝服务攻击
static final int UNTREEIFY_THRESHOLD = 6; // 单个桶中数量小于门限, 则会退化成链表
static final int MIN_TREEIFY_CAPACITY = 64; // 最小的树化容量, 当Map的容量小于该值时, 如果一个桶的元素过多, 会首先采用扩容方法尝试缓解. 超过该值时, 如果达到TREEIFY-THRESH则会树化
```

#### 构造器
从构造器开始看, `HashMap`提供了以下几种构造器
```java
public HashMap(int initialCapacity, float loadFactor)
public HashMap(int initialCapacity)
public HashMap()
public HashMap(Map<? extends K, ? extends V> m)
```
后面的几种构造函数, 无非就是将一些参数设为了默认值, 我们直接看第一个构造器
```java
    public HashMap(int initialCapacity, float loadFactor) {
        // 判断initialCapacity和loadFactor的合法性, 大于0, 不为NaN等
        this.loadFactor = loadFactor;
        this.threshold = tableSizeFor(initialCapacity);
    }
```
这个构造器总共就做了两个参数的赋值, 没有其他实际的创建结构,  所以这里其实采用了**懒惰加载**的方法, 在真正调用的时候,才去初始化内部的结构. 

#### tableSizeFor()与容量大小
然后这里的`tableSizeFor()`方法, 其目的是将输入的容量, 转换为大于等于输入容量的2的幂.为什么`HashMap`的容量总要保持2的幂, 我们之后再讨论, 但是这里好像还是不对. 

返回值为什么是赋值给的`threshold`, 这个参数不是扩容的门限值么? 
 其实这个参数的解释是: *如果table数组还没有被创建, 这个参数等于数组的初始大小, 如果为0则采用默认初始大小.* 

接着我们看一看`tableSizeFor`是怎么转成2的幂的
```java
// 1.8的实现
static final int tableSizeFor(int cap) {
        int n = cap - 1;
        n |= n >>> 1;
        n |= n >>> 2;
        n |= n >>> 4;
        n |= n >>> 8;
        n |= n >>> 16;
        return (n < 0) ? 1 : (n >= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;
    }

// 早期版本的实现
int capacity = 1;
while (capacity < initialCapacity)
    capacity <<= 1;  
```
从早期版本实现, 我们很容易看懂, 就是找一个最小的2的幂, 大于等于`initalCapacity`嘛, 但是新版的好像就有点懵了, 这是在干什么, 我们不妨举个例子.
1. 假设我们的输入是65, 二进制0100 0001, 减1得到0100 0000
2. 注意观察最高位的1, 当第一次右移, 然后做或运算, (0100 0000 |0010 0000) = 0110 0000
3. 这样最高位的1就变成了两个1, 接着做右移 2位, 然后或运算, (0110 0000 | 0001 1000) = (0111 1000)
4. 现在从最高位往右就有至少4个1了, 再用它们往右移4位覆盖低位, 最终得到的从最高位开始往右都是1的结果, 0111 1111
5. 最后加1, 得到了1000 0000, 128

这样相比原来循环1位一位往上移, 又快了一些, 如果还没有看懂, 可以看下这个[参考资料](https://blog.csdn.net/huzhigenlaohu/article/details/51802457), 里面带了一些示意图.

#### put函数
接下来看下具体的初始化工作.  初始化发生在第一次`put`, 这个函数只有一行, 但是有个细节, 这里用`hash`函数处理了key, 然后再进行实际的`putVal`操作.
```java
public V put(K key, V value) {
        return putVal(hash(key), key, value, false, true);
    }
 ```
#### hash函数
我一开始以为, hash函数只是返回了`key.hashCode()`的值, 然后发现并不是.
```java
// 1.8
static final int hash(Object key) {
       int h;
       return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
   }
// 以往版本
h ^= (h >>> 20) ^ (h >>> 12);
return h ^ (h >>> 7) ^ (h >>> 4);
```
在 JDK1.8 的实现中，将 hashCode 的高 16 位与 hashCode 进行异或运算，主要是为了在 table 的 length 较小的时候，让高位也参与运算，并且不会有太大的开销。为什么比以往版本的hash有所简化, 我所看到的资料主张是因为加入了树化后, 碰撞情况的查找成本小了, 所以hash的计算可以简化.

#### put的实际执行函数putVal
这个函数是整个类中, 逻辑最密集的之一, 所以相当精彩,  函数中要做的包括懒惰加载-初始化, 检查是否key已经存在, 检查是否要树化等.

```java
/**
     * Implements Map.put and related methods
     *
     * @param hash 经过hash函数得到的hash值
     * @param key the key
     * @param value the value to put
     * @param onlyIfAbsent 为true时, 如果已经存在就不修改
     * @param evict if false, the table is in creation mode.
     * @return previous value, or null if none
     */
    final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
                   boolean evict) {
        Node<K,V>[] tab; Node<K,V> p; int n, i;
        if ((tab = table) == null || (n = tab.length) == 0) // 如果首次调用, 进行初始化
            n = (tab = resize()).length; // resize函数进行初始化
        if ((p = tab[i = (n - 1) & hash]) == null) // (n - 1) & hash相当于hash对n取模, 详细看后面的解释. 
        // 如果找到的桶为空, 则key肯定不存在
            tab[i] = newNode(hash, key, value, null);
        else {
            Node<K,V> e; K k;
            // p是桶的头节点 e是p的后一个节点, 两个指针一前一后遍历链表
            if (p.hash == hash &&
                ((k = p.key) == key || (key != null && key.equals(k)))) // 如果头结点就是要找的key的node
                e = p;
            else if (p instanceof TreeNode) // 如果头节点是个树节点, 则调用树插入
                e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value); // 如果有key, e=node 否则e = null
            else {
                for (int binCount = 0; ; ++binCount) {
                    if ((e = p.next) == null) { // 如果整个链没有找到, e= null
                        p.next = newNode(hash, key, value, null); // 创建一个新节点
                        if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
                            treeifyBin(tab, hash); // 如果达到树化条件, 则树化或扩容
                        break;
                    }
                    if (e.hash == hash && // 找到了key
                        ((k = e.key) == key || (key != null && key.equals(k))))
                        break;
                    p = e; // 和e = p.next 构成链表往下走
                }
            }
            if (e != null) { // existing mapping for key
            // 找到key所在节点, 修改value并返回旧值   
            }
        }
        ++modCount;
        if (++size > threshold) // 超过门限, 扩容
            resize();
        afterNodeInsertion(evict);
        return null;
    }
```
这里留个悬念, 为什么在创建新节点的时候, 调用的是`newNode()`方法而不是直接`new Node()`产生一个对象? [linkedHashMap]
#### resize方法
resize函数是另一个重要的方法, 其功能包括初始化和扩容

```java
final Node<K,V>[] resize() {
        Node<K,V>[] oldTab = table;
        int oldCap = (oldTab == null) ? 0 : oldTab.length;
        int oldThr = threshold;
        int newCap, newThr = 0;
        if (oldCap > 0) {
            if (oldCap >= MAXIMUM_CAPACITY) {
               // 不进行扩容
            }
            else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&
                     oldCap >= DEFAULT_INITIAL_CAPACITY)
                newThr = oldThr << 1; // double threshold
        }
        else 
        //  初始化时, thresh的值不为0, 则按照thresh初始化, 否则按照默认的初始化容量初始化
        if (newThr == 0) {
            float ft = (float)newCap * loadFactor;
            newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ?
                      (int)ft : Integer.MAX_VALUE);
        }
        threshold = newThr;
        @SuppressWarnings({"rawtypes","unchecked"})
            Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];
        table = newTab; // 创建新的table
        if (oldTab != null) { // 非初始化, 则需要从旧数组移动到新数组
            for (int j = 0; j < oldCap; ++j) {
                Node<K,V> e;
                if ((e = oldTab[j]) != null) {
                    oldTab[j] = null;
                    if (e.next == null)
                        newTab[e.hash & (newCap - 1)] = e;
                    else if (e instanceof TreeNode)
                        ((TreeNode<K,V>)e).split(this, newTab, j, oldCap); // 让树自己拆分并放置到新数组中
                    else { // preserve order // 尾插法保持顺序
                    // 如果(e.hash & oldCap) == 0 则留在原桶中, 否则进入新桶
                    }
                }
            }
        }
        return newTab;
    }
```

#### 树化Treeify
树化是JDK1.8中HashMap实现的一大亮点, 代码量也很多, 如果一起分析的话, 篇幅过长了, 但是这个放一个关于树化部分的代码分析的[文章](https://www.cnblogs.com/finite/p/8251587.html), 供大家参考.

#### HashMap常考知识点总结
- 为什么要保证容量是2的幂?
对于任意给定的对象，只要它的 hashCode() 返回值相同，那么计算得到的 hash 值总是相同的。我们首先想到的就是把 hash 值对 table 长度取模运算，这样一来，元素的分布相对来说是比较均匀的。
但是模运算消耗还是比较大的，我们知道计算机比较快的运算为位运算，因此 JDK 团队对取模运算进行了优化，使用上面代码2的位与运算来代替模运算。这个方法非常巧妙，它通过 “(table.length -1) & h” 来得到该对象的索引位置，这个优化是基于以下公式：$x mod 2^n = x \& (2^n - 1)$。我们知道 HashMap 底层数组的长度总是 2 的 n 次方，并且取模运算为 “h mod table.length”，对应上面的公式，可以得到该运算等同于“h & (table.length - 1)”。这是 HashMap 在速度上的优化，因为 & 比 % 具有更高的效率。

- 为什么要链表要从头插法变成尾插法? 
头插法还是尾插法指的都是`resize`函数, 在将节点移动到新的桶中时, 节点如何插入的方法, 头插法的考量是后插入的数据可能是热点数据, 头插更容易访问, 但是存在的问题是头插法在每次resize的时候, 节点之间的前后关系都是倒置, 所以这种优化并不成立. 然而, 在下面的竞态条件下,头插法可能引起链表成环, 而尾插法不会, 因此当被错误用在并发情形下, 尾插法只有可能丢失一部分数据, 而头插法会导致死循环, 彻底不可用.

- 如果把HashMap用在并发情形下, 会导致的问题?
出现很典型的竞态条件, 在resize中将链表变成环导致resize无限循环, cpu占用, HashMap无法正常继续.[具体情形](https://mailinator.blogspot.com/2009/06/beautiful-race-condition.html)这篇博客讲的很清楚, 还带有配图.

### LinkedHashMap
前面对Collection包中非常重要的一个类`HashMap`进行了分析和总结, 但是`HashMap`存在一些问题, 最重要的是**HashMap不能够保证存储元素的有序性**, 这一点是因为HashMap的遍历是按照桶顺序的, 而节点的插入顺序和桶的顺序无关, 并且还会在resize的时候进一步打乱. 那有没有既能够在常数时间进行增删改查又能够保持有序的Map呢, 于是就有了`LinkedHashMap`.
 
`LinkedHashMap`是`HashMap`的子类, 所以其落脚点是`HashMap`, 在其基础上, 通过一个双向链表将节点按照**插入顺序或访问顺序**连接起来, 就能够以较低的成本达到上述的有序的目标.

同时, 因为其实现了按照访问顺序的排序, 所以也是天然的LRU容器, 官方的文档中就有建议, 可以用它来作为LRU缓存, 按照一定的规则删除最老的节点, 例如当size超过一个值时, 删除最长时间未访问的元素. 在文章的最后, 笔者也实现了一个基于`LinkedHashMap`的LRU管理的demo. 另一方面, 因为是`HashMap`的子类,`LinkedHashMap`也不能保证线程安全, 如果需要进行并发, 需要使用它的`synchronized`的装饰版本. 本文的所有源码分析都是基于**JDK1.8版本**.

#### Constructor
`LinkedHashMap`和`HashMap`的构造器基本一致, 但是多了`accessOrder`参数, 当它为`false`时, 按照链表按照插入顺序排序, 当它为true时, 链表按照访问顺序排序
```java
// 其他构造器都无法传入accessOrder参数
public LinkedHashMap(int initialCapacity,  float loadFactor, boolean accessOrder)
```
对元素的put, putIfAbsent, get, getOrDefault, compute , computeIfAbsent, computeIfPresent, merge操作(假设元素存在)都视作对元素的访问, replace只有元素被替换的时候才视作一次访问, putAll方法对传入的每个元素产生一次访问, 访问的顺序取决于输入的Map的iterator提供的顺序.
#### Entry
Entry类是`HashMap.Node`的子类, 它在`Node`的基础上增加了两个成员变量, `before`和`after`. 因此`Entry`类中有三个指针: `before`和`after`分别指向双向链表的前一个节点和后一个节点, 而`next`指向桶中的链的下一个节点.
```java
static class Entry<K,V> extends HashMap.Node<K,V> {
        Entry<K,V> before, after;
        Entry(int hash, K key, V value, Node<K,V> next) {
            super(hash, key, value, next);
        }
    }
```
因此, `LinkedHashMap`的结构示意图大致是这样, ![在这里插入图片描述](https://img-blog.csdn.net/20170512160734275?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvanVzdGxvdmV5b3Vf/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
接下来的问题就是, 添加和删除节点时link是如何处理的, 以及, 当节点被访问时, 在链表中的顺序调整是怎样实现的, 以及, 如果要用它实现LRU应当怎么做.

#### 添加和删除
**putVal**

`LinkedHashMap`没有重写`put`方法, 而是利用`HashMap`中`putVal`的良好设计, 对`afterNodeAccess`和`afterNodeInsertion`两个回调函数以及`newNode`方法进行重写.
我们首先回顾一下`HashMap.putVal`方法
```java
final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
                   boolean evict) {
        Node<K,V>[] tab; Node<K,V> p; int n, i;
        // 懒惰加载初始化
        if ((p = tab[i = (n - 1) & hash]) == null)
            tab[i] = newNode(hash, key, value, null); // 注意这里不是new Node( )
        else {
            // 在桶的链表或树中查找key, 如果不存在也是调用newNode方法创建
            // 如果超过阈值, 进行树化
            }
            if (e != null) { // 如果key存在
                ...
                afterNodeAccess(e);
                return oldValue;
            }
        }
        // 递增modCount, 并判断是否扩容
        afterNodeInsertion(evict);
        return null;
    }
```
注意这里的`newNode`函数, 是设计模式中的`工厂模式`, 有普通Node和TreeNode两个版本, 在`HashMap`中, 内部就是简单的调用了`new`产生一个新的实例返回, 但是`LinkedHashMap`通过重写这两个函数, 除了返回一个新对象, 还将这个对象添加到链表尾.

此外, `LinkedHashMap`重写了`afterNodeInsertion`回调函数, 判断是否要将链表表头的元素删除(删除最老的节点), 重写了`afterNodeAccess`回调函数, 如果是按照访问顺序排序的话, 将被访问的节点移动到链表的末尾.

注意在JDK1.8以前, 这两个函数分别是`Entry.recordAccess`和`addEntry`, 1.8把这两个函数的逻辑部分移到putVal中, 而抽象出两个回调函数, 供子类重写, 逻辑上更加的清晰, 也符合面向对象中的**开闭原则**(开放扩展, 关闭修改).

**removeNode**

在`remove`操作中, 类似的, `HashMap`提供了`afterNodeRemoval`回调函数, 而`LinkedHashMap`重写了它, 做了双向链表的删除节点操作.

#### 按照访问顺序排序
之前提到了`afterAccess`回调函数中, 实现了将被访问节点移动到队尾的操作, 源码也就是对双向链表的一个操作.
```java
 void afterNodeAccess(Node<K,V> e) { // move node to last
        LinkedHashMap.Entry<K,V> last;
        if (accessOrder && (last = tail) != e) {
            LinkedHashMap.Entry<K,V> p =
                (LinkedHashMap.Entry<K,V>)e, b = p.before, a = p.after;
            p.after = null;
            if (b == null)
                head = a;
            else
                b.after = a;
            if (a != null)
                a.before = b;
            else
                last = b;
            if (last == null)
                head = p;
            else {
                p.before = last;
                last.after = p;
            }
            tail = p;
            ++modCount;
        }
    }
```
然后在`HashMap`中, 在下面这些函数中, 去调用这个回调函数就能够实现将最近被访问的节点安排在队尾.
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200224163011143.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzM3NDA3NTg3,size_16,color_FFFFFF,t_70)
#### 将最久没有访问的节点删除
上面提到, 每次插入时, 就会调用`afterNodeInsertion`这个回调函数, 因此`LinkedHashMap`通过重写这个函数, 来判断是否将最不长访问的节点删除(队首的节点)
```java
void afterNodeInsertion(boolean evict) { // possibly remove eldest
        LinkedHashMap.Entry<K,V> first;
        if (evict && (first = head) != null && removeEldestEntry(first)) {
            K key = first.key;
            removeNode(hash(key), key, null, false, true);
        }
    }
```
注意`removeEldestEntry(first)`函数就是判断第一个节点是否应该被删除的条件, 这个函数在源码中默认为返回false的.
```java
protected boolean removeEldestEntry(Map.Entry<K,V> eldest) {
        return false;
    }
```
重写它, ~~你就能获得力量~~就能够用来控制LRU策略. 所以最后, 我们一起来写一个demo用`LinkedHashMap`来手写一个LRU.

#### LinkedHashMap 手写LRU
```java
public class MyLRUSample {
    public static void main(String[] args) {
        LinkedHashMap<Integer, String> LRU 
                = new LinkedHashMap<Integer, String>(16, 0.75F, true) {
            @Override
            protected boolean removeEldestEntry(Map.Entry<Integer, String> eldest) {
                return size() > 4; // 当缓存超过4个时, 删除最不长访问的
            }
        };
        LRU.put(1, "1");LRU.put(2, "2");LRU.put(3, "3");LRU.put(4, "4");
        System.out.println("Original order in LRU");
        
        LRU.forEach((k,v)->System.out.println(k + ":" + v));
        LRU.get(3);LRU.get(4);LRU.put(2, "Two");LRU.get(3);
        System.out.println("After some accesses, the order in LRU");
        LRU.forEach((k,v)->System.out.println(k + ":" + v));
        
        LRU.put(5, "5");
        System.out.println("1 has been removed.");
        LRU.forEach((k,v)->System.out.println(k + ":" + v));
    }
}
```
输出:
```
Original order in LRU
1:1
2:2
3:3
4:4
After some accesses, the order in LRU
1:1
4:4
2:Two
3:3
1 has been removed.
4:4
2:Two
3:3
5:5
```
结果和预期一致, 同时注意到, 重写过的`iterator`的访问顺序是从链表头到链表尾的.

